{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Classes    \n",
    "\n",
    "Import modules that may be needed afterwards to test the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general use modules\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "# The classes should help the use of `Pipeline` and `GridSearchCV`\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Sample DataSet and tools to test and debug the classes\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics  import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sample classes with `transform` method\n",
    "from sklearn.preprocessing import StandardScaler, Binarizer\n",
    "\n",
    "# Sample classes with  `predict`  method\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "Preparations for testing & debugging.  \n",
    "*Note: Computations and tests that have been made on the fly have been deleted*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dimensions: (398, 30)\n",
      "Test Dimensions: (171, 30)\n"
     ]
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "ftrs = pd.DataFrame(cancer.data, columns= cancer.feature_names)\n",
    "trgt = pd.Series(cancer.target)\n",
    "\n",
    "# selected columns @ iloc 1,0,3 and 1,0,3,2 accordingly\n",
    "cols_1 = ['mean texture', 'mean radius', 'mean area']\n",
    "cols_2 = cols_1 + ['mean perimeter']\n",
    "\n",
    "# Split the data as pd.DataFrame & pd.Series\n",
    "X_train, X_test, y_train, y_test = train_test_split(ftrs, trgt,\n",
    "                                                    test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the data as np.array\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(cancer.data, cancer.target,\n",
    "                                                        test_size=0.3, random_state=42)\n",
    "\n",
    "# print dimensions\n",
    "print(f\"Train Dimensions: {X_train2.shape}\",\n",
    "      f\"Test Dimensions: {X_test2.shape}\", sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### `class ClfSwitcher(BaseEstimator):`\n",
    "\n",
    "```\n",
    "ClfSwitcher is responsible for estimating multiple classifiers in a single pipeline.\n",
    "By default it takes the default parameters for any Classifier using BaseEstimator sklearn class.\n",
    "\n",
    "Args:\n",
    "    estimator (Object) : Input Classifier\n",
    "```\n",
    "```python\n",
    "Example:\n",
    "    In [1]: pipeline = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('clf', ClfSwitcher())\n",
    "            ])\n",
    "\n",
    "            parameters = [\n",
    "                {\n",
    "                    'clf__estimator': [RandomForestClassifier()],\n",
    "                    'clf__estimator__n_estimators': [1,3,6,9,12,15]\n",
    "                },\n",
    "                {\n",
    "                    'clf__estimator': [LogisticRegression()],\n",
    "                    'clf__estimator__solver': ['lbfgs']\n",
    "                }\n",
    "            ]\n",
    "\n",
    "            gscv = GridSearchCV(pipeline, parameters, ...)\n",
    "            gscv.fit(X_train)\n",
    "            print(gscv.best_params_['clf__estimator'])\n",
    "            \n",
    "    Out[1]: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                               intercept_scaling=1, max_iter=100, multi_class='warn',\n",
    "                               n_jobs=None, penalty='l2', random_state=None, solver='lbfgs', \n",
    "                               tol=0.0001, verbose=0, warm_start=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules needed\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class ClfSwitcher(BaseEstimator):\n",
    "\n",
    "    def __init__(self, estimator = None):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.estimator.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        return self.estimator.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.estimator.predict_proba(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.estimator.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `class ColumnSelector(BaseEstimator, TransformerMixin):`    \n",
    " \n",
    "\n",
    "```\n",
    "ColumnSelector Class transforms the fitted Dataset and selects the desired the columns/features.\n",
    "It can be used with sklearn `Pipeline` and `GridSearchCV`.\n",
    "\n",
    "Args:\n",
    "    subset (None):    Input columns/features to select from the fitted Dataset.\n",
    "    reference (None): Input the full column/feature list if needed.\n",
    "    args dtypes:      list, tuple, np.array, pd.Series, pd.DataFrame, None\n",
    "```\n",
    "```python\n",
    "Examples:\n",
    "    \n",
    "    In [1]: df = pd.DataFrame({'A': [1,2,3], 'B': [4,5,6], 'C': [7,8,9]})\n",
    "            cols = ['A','C']\n",
    "            pipeline_A = Pipeline([\n",
    "                ('select', ColumnSelector(cols)),\n",
    "            ])\n",
    "            print(pipeline_A.fit_transform(df))\n",
    "            \n",
    "    Out[1]:    A  C\n",
    "            0  1  7\n",
    "            1  2  8\n",
    "            2  3  9\n",
    "            \n",
    "    In [2]: arr = np.array(df)\n",
    "            lst = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "            \n",
    "            pipeline_B = Pipeline([\n",
    "                ('select', ColumnSelector(cols,df.columns)),\n",
    "            ])\n",
    "            \n",
    "            pipeline_C = Pipeline([\n",
    "                ('select', ColumnSelector([0,2])),\n",
    "            ])\n",
    "            \n",
    "            # Pipeline A\n",
    "            A0 = pipeline_A.transform(df)\n",
    "            # Pipeline B\n",
    "            B0 = pipeline_B.transform(arr)\n",
    "            B1 = pipeline_B.transform(lst)\n",
    "            # Pipeline C\n",
    "            C0 = pipeline_C.transform(arr)\n",
    "            C1 = pipeline_C.transform(lst)\n",
    "            # Compare if all Transforms are the Same\n",
    "            print(all(A0 & B0 & B1 & C0 & C1))\n",
    "            \n",
    "    Out[2]: True     \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules needed\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, subset=None, reference=None):\n",
    "        self.subset = subset\n",
    "        self.ref = reference\n",
    "    \n",
    "    def fit(self,*args, **kwargs):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, *args, **kwargs):\n",
    "        if 'subset' in kwargs:\n",
    "            self.subset = kwargs['subset']\n",
    "        if 'reference' in kwargs:\n",
    "            self.ref = kwargs['reference']\n",
    "            \n",
    "        if self.subset is None:\n",
    "            self.data = X\n",
    "            \n",
    "        elif isinstance(X, (list,tuple,np.ndarray)):\n",
    "            subset = np.array(self.subset)\n",
    "\n",
    "            if isinstance(X[0],(list,tuple)):\n",
    "                data = np.array(X).T\n",
    "            else:\n",
    "                data = np.array(X)\n",
    "              \n",
    "            if self.ref is None:\n",
    "                try:\n",
    "                    subset = subset.astype(np.int8)\n",
    "                except:\n",
    "                    raise ValueError(\"`reference` param needs to be assigned\")\n",
    "            else:\n",
    "                ref = np.array(self.ref)\n",
    "                def subset_idx(x):\n",
    "                    return np.where(ref == x)[0][0]\n",
    "                subset = np.vectorize(subset_idx)(subset)\n",
    "        \n",
    "            self.data = data[:,subset]\n",
    "\n",
    "        elif isinstance(X, pd.DataFrame):\n",
    "            self.data = X.loc[:, self.subset]\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Does not support this dtype. Consult help()\")\n",
    "        \n",
    "        return self.data            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Class Testing    \n",
    "    \n",
    "1. ***Set a sample `Pipeline` & parameters for a `GridSearchCV`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('select', ColumnSelector()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', ClfSwitcher()),\n",
    "])\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        'select__subset': [cols_1],\n",
    "        'clf__estimator': [RandomForestClassifier()],\n",
    "        'clf__estimator__n_estimators': [1,3,6,9,12,15],\n",
    "    },\n",
    "    {\n",
    "        'select__subset': [cols_2],\n",
    "        'clf__estimator': [SGDClassifier()], # SVM if hinge loss / logreg if log loss\n",
    "        'clf__estimator__penalty': ('l2', 'elasticnet', 'l1'),\n",
    "        'clf__estimator__max_iter': [50, 80],\n",
    "        'clf__estimator__tol': [1e-4],\n",
    "        'clf__estimator__loss': ['hinge', 'log', 'modified_huber'],\n",
    "    },\n",
    "    {\n",
    "        'select__subset': [cols_1[0:2]],\n",
    "        'clf__estimator': [LogisticRegression()],\n",
    "        'clf__estimator__solver': ['lbfgs'],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ***Run `ColumnSelector` in the `Pipeline`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean perimeter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>17.91</td>\n",
       "      <td>13.74</td>\n",
       "      <td>585.0</td>\n",
       "      <td>88.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>16.39</td>\n",
       "      <td>13.37</td>\n",
       "      <td>553.5</td>\n",
       "      <td>86.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>13.98</td>\n",
       "      <td>14.69</td>\n",
       "      <td>656.1</td>\n",
       "      <td>98.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean texture  mean radius  mean area  mean perimeter\n",
       "149         17.91        13.74      585.0           88.12\n",
       "124         16.39        13.37      553.5           86.10\n",
       "421         13.98        14.69      656.1           98.22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_short = pipeline.named_steps['select'].transform(X_train, subset=cols_2)\n",
    "\n",
    "X_train_short.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ***Run the classes in a `GridSearchCV`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USED FEATURES:\n",
      "\n",
      "['mean texture', 'mean radius', 'mean area', 'mean perimeter']\n",
      "\n",
      "BEST MODEL & PARAMS:\n",
      "\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=50,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "\n",
      "PREDICTED VAVLUES:\n",
      "\n",
      "[1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 0\n",
      " 1 1 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0\n",
      " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 out of  75 | elapsed:    2.3s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:    2.4s finished\n"
     ]
    }
   ],
   "source": [
    "gscv = GridSearchCV(pipeline, parameters, cv=3, n_jobs=-1, return_train_score=True, iid= False, verbose=3)\n",
    "\n",
    "gscv.fit(X_train, y_train)\n",
    "\n",
    "print('USED FEATURES:', gscv.best_params_[\"select__subset\"],\n",
    "      'BEST MODEL & PARAMS:', gscv.best_params_['clf__estimator'],\n",
    "      'PREDICTED VAVLUES:', gscv.predict(X_test),sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ***Presenting the results in a Confusion Matrix***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>malignant</th>\n",
       "      <th>benign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>malignant</th>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benign</th>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           malignant  benign\n",
       "malignant         50      13\n",
       "benign             2     106"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = gscv.predict(X_test)\n",
    "conf_mtrx  = confusion_matrix(y_test, prediction)\n",
    "\n",
    "pd.DataFrame(conf_mtrx,\n",
    "             columns=cancer.target_names, index=cancer.target_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
